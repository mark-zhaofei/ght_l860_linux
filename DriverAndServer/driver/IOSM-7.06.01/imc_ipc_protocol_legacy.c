/*
 * Copyright (C) 2016-2017 Intel Deutschland GmbH
 * Copyright (C) 2018 Intel Corporation
 *
 * SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0)
 *
 */

#include <linux/pci.h>
#include <linux/seq_file.h>

#include "imc_ipc_protocol.h"
#include "imc_ipc_protocol_priv.h"
#include "imc_ipc_protocol_legacy.h"
#include "imc_ipc_pm.h"
#include "imc_ipc_trace.h"
#include "imc_ipc_pcie.h"
#include "imc_ipc_imem.h"
#include "imc_ipc_dbg.h"
#include "imc_ipc_util.h"
#include "imc_ipc_mmio.h"



/**
 *Head pointer definition.
 */
#define ipc_mem_head_ptr_t	u32

/**
 * Tail pointer definition.
 */
#define ipc_mem_tail_ptr_t	u32


/**
 * Structure of the context info.
 */
struct ipc_legacy_context_info {
	/* 64 bit address to device info */
	u64 device_info_addr;
	/* 64 bit address to head pointer array for the pipes */
	u64 head_ptr_array;
	/* 64 bit address to tail pointer array for the pipes */
	u64 tail_ptr_array;
	/* 64 bit address to message head pointer */
	u64 msg_head_ptr;
	/* 64 bit address to message tail pointer */
	u64 msg_tail_ptr;
	/* 64 bit pointer to the message ring buffer */
	u64 msg_ring_addr;
	/* This field provides the number of entries which the MR can hold. */
	u32 msg_ring_entries:16;
	/* This field provides the IRQ which shall be
	 * generated by the EP device when
	 * generating completion for Messages.
	 */
	u32 msg_irq_vector:5;
	/* This field provides the IRQ which shall be
	 * generated by the EP device after
	 * updating Device Information.
	 */
	u32 device_info_irq_vector:5;
	u32 reserved:6;
};


/**
 * Structure for the device information.
 */
struct ipc_legacy_device_info {
	u32 execution_stage;
	u32 ipc_status;
	u32 device_sleep_notification;
};


/**
 * Type-definition of the messages.
 */
enum ipc_mem_msg {
	/* AP ->CP: Open a pipe */
	IPC_MEM_MSG_OPEN_PIPE = 0x01,

	/* AP ->CP: Close a pipe */
	IPC_MEM_MSG_CLOSE_PIPE = 0x02,

	/* AP ->CP: wait for completion of the running transfer
	 * and abort all pending IO-transfers for the pipe
	 */
	IPC_MEM_MSG_ABORT_PIPE = 0x03,

	/* AP ->CP: host enter or exit sleep */
	IPC_MEM_MSG_SLEEP = 0x04,

	/**< AP ->CP: Intel feature configuration */
	IPC_MEM_MSG_FEATURE_SET = 0xF0,
};


/**
 * Completion status of a TD
 */
enum ipc_mem_td_cs {
	/* Initial status - td not yet used. */
	IPC_MEM_TD_CS_INVALID = 0,
	/* More data pending -> next TD used for this. */
	IPC_MEM_TD_CS_PARTIAL_TRANSFER = 1,
	/* IO transfer is complete. */
	IPC_MEM_TD_CS_END_TRANSFER = 2,
	/* IO transfer to small for the buffer to write. */
	IPC_MEM_TD_CS_OVERFLOW = 3,
	/* TD marked as abort and shall be discarded by AP. */
	IPC_MEM_TD_CS_ABORT = 4,
	/* General error. */
	IPC_MEM_TD_CS_ERROR = 5
};


/**
 * Message structure for open pipe.
 */
struct ipc_mem_msg_open_pipe {
	u64 tdr_addr;
	u32 tdr_entries:16;
	u32 pipe_nr:8;
	u32 type_of_message:8;
	u32 irq_vector:5;
	u32 optimized_completion:1;
	u32 reliable:1;
	u32 reserved1:1;
	u32 interrupt_moderation:24;
	u32 accumulation_backoff:24;
	u32 reserved2:8;
	u32 completion_status;
};

/**
 * Message structure for close pipe.
 */
struct ipc_mem_msg_close_pipe {
	u64 reserved1;
	u32 reserved2:16;
	u32 pipe_nr:8;
	u32 type_of_message:8;
	u32 reserved3;
	u32 reserved4;
	u32 completion_status;
};

/**
 * Message structure for abort pipe.
 */
struct ipc_mem_msg_abort_pipe {
	u64 reserved1;
	u32 reserved2:16;
	u32 pipe_nr:8;
	u32 type_of_message:8;
	u32 reserved3;
	u32 reserved4;
	u32 completion_status;
};

/**
 * Message structure for sleep message.
 */
struct ipc_mem_msg_host_sleep {
	u64 reserved1;
	/* 0=host, 1=device, host or EP devie is the message target */
	u32 target:8;
	/* 0=enter sleep, 1=exit sleep, 2=enter sleep no protocol */
	u32 state:8;
	u32 reserved2:8;
	/* message type */
	u32 type_of_message:8;
	u32 reserved3;
	u32 reserved4;
	u32 completion_status;
};

/**
 * Message structure for feature_set message
 */
struct ipc_mem_msg_feature_set {
	u64 reserved1;
	u32 reserved2:23;
	u32 reset_enable:1;
	u32 type_of_message:8;
	u32 reserved3;
	u32 reserved4;
	u32 completion_status;
};

/**
 * Message structure for completion status update.
 */
struct ipc_mem_msg_common {
	u64 reserved1;
	u32 reserved2:24;
	u32 type_of_message:8;
	u32 reserved3;
	u32 reserved4;
	u32 completion_status;
};

/**
 * Union with all possible messages.
 */
union ipc_mem_msg_entry {
	struct ipc_mem_msg_open_pipe open_pipe;
	struct ipc_mem_msg_close_pipe close_pipe;
	struct ipc_mem_msg_abort_pipe abort_pipe;
	struct ipc_mem_msg_host_sleep host_sleep;
	struct ipc_mem_msg_feature_set feature_set;
	/* Used to access msg_type and to set the completion status.
	 */
	struct ipc_mem_msg_common common;
};


/**
 * Legacy Protocol Shared Memory Structure
 */
struct ipc_legacy_ap_shm {
	struct ipc_legacy_context_info ci;
	struct ipc_legacy_device_info device_info;

	ipc_mem_head_ptr_t msg_head_ptr;
	ipc_mem_head_ptr_t head_ptr_array[IPC_MEM_MAX_PIPES];
	ipc_mem_tail_ptr_t msg_tail_ptr;
	ipc_mem_tail_ptr_t tail_ptr_array[IPC_MEM_MAX_PIPES];

	/* Circular buffers for the read/tail and write/head indeces.
	 */
	union ipc_mem_msg_entry msg_ring[IPC_MEM_MSG_ENTRIES];

};


/**
 * Legacy Protocol Shared Memory Structure
 */
struct ipc_legacy {
	struct ipc_legacy_ap_shm *p_ap_shm;
	/* Physical/Mapped representation of the shared memory information.
	 */
	u64 phy_ap_shm;

	/* Old msg tail ptr, until AP has handled ACK's from CP
	 */
	ipc_mem_tail_ptr_t old_msg_tail_ptr;

	/* Power management */
	struct ipc_pm *pm;
	struct ipc_pcie *p_pcie;
	struct ipc_debugfs_stats *p_stats;

	/* pointer to ipc_dbg structure */
	struct ipc_dbg *dbg;
};


/**
 * Transfer descriptor definition.
 */
struct ipc_legacy_td {
	union {
		/*   0 :  63 - 64-bit address of a buffer in host memory. */
		u64 address;
		struct __attribute__ ((__packed__)) {
			/*   0 :  31 - 32 bit address */
			u32 address;
			/*  32 :  63 - corresponding descriptor */
			u32 desc;
		} shm;
	} buffer;

	struct __attribute__ ((__packed__)) {
		/*  64 :  87 - Size of the buffer.
		 *             The host provides the size of the buffer queued.
		 *             The EP device reads this value and shall update
		 *             it for downlink transfers to indicate the
		 *             amount of data written in buffer.
		 */
		u32 size:24;
		/*  88 :  95 - This field provides the completion status
		 *             of the TD. When queuing the TD, the host sets
		 *             the status to 0. The EP device updates this
		 *             field when completing the TD.
		 */
		u32 completion_status:8;
	} scs;

	/*  96 : 103 - nr of following descriptors */
	u32 next:8;
	/* 104 : 127 - reserved */
	u32 reserved1:24;
} __attribute__ ((__packed__));


/**
 * Get the next free message element.
 *
 * @this: Pointer to ipc_legacy instance
 * @index: Pointer to index result.
 *         On success, will be set to index of the allocated message
 *
 * returns Pointer to ipc_mem_msg_entry
 */
static union ipc_mem_msg_entry *ipc_legacy_free_msg_get(
		struct ipc_legacy *this, int *index)
{
	ipc_mem_head_ptr_t head = this->p_ap_shm->msg_head_ptr;
	ipc_mem_head_ptr_t new_head = (head + 1) % IPC_MEM_MSG_ENTRIES;
	union ipc_mem_msg_entry *msg = NULL;

	if (unlikely(new_head == this->p_ap_shm->msg_tail_ptr)) {
		ipc_err("message ring is full");
		return NULL;
	}

	/* Get the pointer to the next free message element,
	 * reset the fields and mark is as invalid.
	 */
	msg = &this->p_ap_shm->msg_ring[head];
	memset(msg, 0, sizeof(union ipc_mem_msg_entry));

	/* return index in message ring */
	*index = head;

	return msg;
}


/**
 * Updates the message ring Head pointer.
 *
 * @this: Pointer to ipc_legacy instance
 *
 * returns none
 */
static void ipc_legacy_msg_hp_update(void *instance)
{
	struct ipc_legacy *this = instance;
	ipc_mem_head_ptr_t head = this->p_ap_shm->msg_head_ptr;
	ipc_mem_head_ptr_t new_head = (head + 1) % IPC_MEM_MSG_ENTRIES;

	/* Update head pointer and fire doorbell.
	 */
	this->p_ap_shm->msg_head_ptr = new_head;
	this->old_msg_tail_ptr = this->p_ap_shm->msg_tail_ptr;

	ipc_pm_signal_hpda_doorbell(this->pm, IPC_HP_MR);
}

/**
 * Allocate and prepare a OPEN_PIPE message.
 * This also allocates the memory for the new TDR structure and
 * updates the pipe structure referenced in the preparation arguments.
 */
static int ipc_legacy_msg_prep_pipe_open(struct ipc_legacy *this,
	union ipc_msg_prep_args *args)
{
	int index = -1;
	union ipc_mem_msg_entry *msg = ipc_legacy_free_msg_get(this, &index);
	struct ipc_pipe *p_pipe = args->pipe_open.pipe;
	struct ipc_legacy_td *tdr;
	struct sk_buff **skbr;

	if (unlikely(!msg)) {
		ipc_err("failed to get free message");
		return -1;
	}

	/* Allocate the skbuf elements for the skbuf which are on the way.
	 * SKB ring is internal memory allocation for driver. No need to
	 * re-calculate the start and end addresses.
	 */
	skbr = ipc_util_kzalloc_atomic(p_pipe->nr_of_entries * sizeof(*skbr));
	if (unlikely(!skbr)) {
		ipc_err("alloc failed");
		return -1;
	}

	/* Allocate the transfer descriptors for the p_pipe.
	 */
	tdr = ipc_pcie_kzalloc(this->p_pcie, p_pipe->nr_of_entries *
			sizeof(struct ipc_legacy_td), &p_pipe->phy_tdr_start);
	if (unlikely(!tdr)) {
		ipc_util_kfree(skbr);
		ipc_err("tdr alloc error");
		return -1;
	}

	/* Initialize the pipe fields.
	 */
	p_pipe->max_nr_of_queued_entries = p_pipe->nr_of_entries - 1;
	p_pipe->nr_of_queued_entries = 0;
	p_pipe->p_tdr_start = tdr;
	p_pipe->skbr_start = skbr;
	p_pipe->old_tail = 0;

	this->p_ap_shm->head_ptr_array[p_pipe->pipe_nr] = 0;

	/* Send the pipe open message to CP.
	 */
	msg->open_pipe.type_of_message = IPC_MEM_MSG_OPEN_PIPE;
	msg->open_pipe.pipe_nr = p_pipe->pipe_nr;
	msg->open_pipe.tdr_addr = p_pipe->phy_tdr_start;
	msg->open_pipe.tdr_entries = p_pipe->nr_of_entries;
	msg->open_pipe.interrupt_moderation = p_pipe->irq_moderation;
	msg->open_pipe.accumulation_backoff = p_pipe->accumulation_backoff;
	msg->open_pipe.reliable = true;
	msg->open_pipe.optimized_completion = true;
	msg->open_pipe.irq_vector = p_pipe->irq;

	ipc_dbg("IPC_MEM_MSG_OPEN_PIPE(pipe_nr=%d, tdr_entries=%d, interrupt_moderation=%d, accumulation_backoff=%d)",
		msg->open_pipe.pipe_nr, msg->open_pipe.tdr_entries,
		msg->open_pipe.interrupt_moderation,
		msg->open_pipe.accumulation_backoff);

	return index;
}

/**
 *  Allocate and prepare a CLOSE_PIPE message
 */
static int ipc_legacy_msg_prep_pipe_close(struct ipc_legacy *this,
	union ipc_msg_prep_args *args)
{
	int index = -1;
	union ipc_mem_msg_entry *msg = ipc_legacy_free_msg_get(this, &index);
	struct ipc_pipe *p_pipe = args->pipe_close.pipe;

	if (unlikely(!msg))
		return -1;

	msg->close_pipe.type_of_message = IPC_MEM_MSG_CLOSE_PIPE;
	msg->close_pipe.pipe_nr = p_pipe->pipe_nr;

	ipc_dbg("IPC_MEM_MSG_CLOSE_PIPE(pipe_nr=%d)",
		msg->close_pipe.pipe_nr);

	return index;
}


/**
 * Allocate and prepare a SLEEP message
 */
static int ipc_legacy_msg_prep_sleep(struct ipc_legacy *this,
	union ipc_msg_prep_args *args)
{
	int index = -1;
	union ipc_mem_msg_entry *msg = ipc_legacy_free_msg_get(this, &index);

	if (unlikely(!msg)) {
		ipc_err("failed to get free message");
		return -1;
	}

	/* Prepare and send the host sleep message to CP to enter or exit D3.
	 */
	msg->host_sleep.type_of_message = IPC_MEM_MSG_SLEEP;
	msg->host_sleep.target = args->sleep.target; /* 0=host, 1=device */

	/* state; 0=enter, 1=exit 2=enter w/o protocol */
	msg->host_sleep.state = args->sleep.state;

	ipc_dbg("IPC_MEM_MSG_SLEEP(target=%d; state=%d)",
		msg->host_sleep.target, msg->host_sleep.state);

	return index;
}

/**
 * Allocate and prepare a FEATURE_SET message
 */
static int ipc_legacy_msg_prep_feature_set(struct ipc_legacy *this,
	union ipc_msg_prep_args *args)
{
	int index = -1;
	union ipc_mem_msg_entry *msg = ipc_legacy_free_msg_get(this, &index);

	if (unlikely(!msg)) {
		ipc_err("failed to get free message");
		return -1;
	}

	msg->feature_set.type_of_message = IPC_MEM_MSG_FEATURE_SET;
	msg->feature_set.reset_enable = args->feature_set.reset_enable;

	ipc_dbg("IPC_MEM_MSG_FEATURE_SET(reset_enable=%d)",
		msg->feature_set.reset_enable);

	return index;
}

/**
 * Processes the message consumed by CP.
 *
 * @this_p: Valid pointer which can be typecasted to ipc_legacy
 * @irq: IRQ number
 * @rsp_ring: pointer to response ring array
 *
 * returns true if any of the message processed otherwise false
 */
static bool ipc_legacy_msg_process(void *instance, int irq,
	struct ipc_rsp **rsp_ring)
{
	struct ipc_legacy *this = instance;
	int i = this->old_msg_tail_ptr;
	bool msg_processed = false;

	if (unlikely(this->p_ap_shm->msg_tail_ptr >= IPC_MEM_MSG_ENTRIES)) {
		ipc_err("msg_tail_ptr out of range: %d",
			this->p_ap_shm->msg_tail_ptr);
		return msg_processed;
	}

	if (irq != IMEM_IRQ_DONT_CARE &&
		irq != this->p_ap_shm->ci.msg_irq_vector)
		return msg_processed;

	while (i != this->p_ap_shm->msg_tail_ptr) {
		union ipc_mem_msg_entry *msg = &this->p_ap_shm->msg_ring[i];

		ipc_dbg("msg[%d]: type=%u status=%d", i,
			msg->common.type_of_message,
			msg->common.completion_status);

		/* Update response with status and wake up waiting requestor */
		if (rsp_ring[i]) {
			rsp_ring[i]->status = (enum ipc_mem_msg_cs)
				msg->common.completion_status;
			ipc_completion_signal(&rsp_ring[i]->completion);
			rsp_ring[i] = NULL;
		}

		i = (i + 1) % IPC_MEM_MSG_ENTRIES;
		msg_processed = true;
	}

	this->old_msg_tail_ptr = i;
	return msg_processed;
}


/**
 * Sends data from UL list to CP for the provided pipe by updating the Head
 * pointer of given pipe.
 *
 * @this_p: Valid pointer which can be typecasted to ipc_legacy.
 * @p_pipe: Pointer to pipe
 * @p_list: Pointer to list of data to be sent to CP
 *
 * returns true: if any data sent to Modem false otherwise
 */
static bool ipc_legacy_ul_td_send(void *this_p, struct ipc_pipe *p_pipe,
		struct imem_ul_queue *p_ul_list)
{
	ipc_mem_head_ptr_t head;
	ipc_mem_tail_ptr_t tail;
	struct ipc_legacy_td *td;
	struct sk_buff *skb;
	struct ipc_skb_cb *skb_cb;
	s32 free_elements = 0;
	bool hpda_pending = false;
	struct ipc_legacy *this = this_p;

	if (unlikely(!this || !p_pipe || !p_ul_list)) {
		ipc_err("Invalid arg(s)");
		return false;
	}

	if (unlikely(!this->p_ap_shm)) {
		ipc_err("Driver is not initialized");
		return false;
	}

	/* Get head and tail of the td list and calculate
	 * the number of free elements.
	 */
	head = this->p_ap_shm->head_ptr_array[p_pipe->pipe_nr];
	tail = p_pipe->old_tail;

	while (!skb_queue_empty(&p_ul_list->list)) {
		if (head < tail)
			free_elements = tail - head - 1;
		else
			free_elements = p_pipe->nr_of_entries - head +
					((s32) tail - 1);

		/* Test the number of free elements.
		 */
		if (free_elements <= 0) {
			ipc_dbg("no free td elements for UL pipe %d",
					p_pipe->pipe_nr);
			break;
		}

		/* Get the td address.
		 */
		td = &p_pipe->p_tdr_start[head];

		/* Take the first element of the uplink list and add it
		 * to the td list.
		 */
		skb = imem_ul_list_dequeue(p_ul_list);
		if (!skb) {
			ipc_dbg("ul_list is empty!");
			break;
		}

		/* DMA sync for ARM based platform only.
		 */
		ipc_pcie_sync_skb_for_device(this->p_pcie, skb);

		/* get the skb control buffer */
		skb_cb = (struct ipc_skb_cb *)skb->cb;

		/* Save the reference to the uplink skbuf. */
		p_pipe->skbr_start[head] = skb;

		/* Define the td fields. */
		td->buffer.address = skb_cb->mapping;
		td->scs.size = skb->len;
		td->scs.completion_status = 0;
		td->next = 0;
		td->reserved1 = 0;

		p_pipe->nr_of_queued_entries++;

		/* Calculate the new head and save it.
		 */
		head++;
		if (head >= p_pipe->nr_of_entries)
			head = 0;

		this->p_ap_shm->head_ptr_array[p_pipe->pipe_nr] = head;
	}

	if (p_pipe->old_head != head) {
		ipc_dbg("new UL TD's Pipe#:%d (old head=%u, new head=%u, tail=%u, free=%d)",
			p_pipe->pipe_nr, p_pipe->old_head, head,
			p_pipe->old_tail, free_elements);

		p_pipe->old_head = head;
		/* Trigger doorbell because of pending UL packets. */
		hpda_pending = true;
	}

	return hpda_pending;
}


/**
 * Checks for Tail pointer update from CP and returns the data as SKB.
 *
 * @this_p: Valid pointer which can be typecasted to ipc_legacy.
 * @p_pipe: Pointer to pipe
 *
 * returns pointer of struct sk_buff if CP consumed data or NULL otherwise.
 */
static struct sk_buff *ipc_legacy_ul_td_process(void *this_p,
		struct ipc_pipe *p_pipe)
{
	struct ipc_legacy_td *p_td;
	struct sk_buff *skb;
	struct ipc_legacy *this = this_p;

	if (unlikely(!this || !p_pipe || !p_pipe->p_tdr_start
	|| !p_pipe->skbr_start)) {
		ipc_err("Invalid arg(s)");
		return NULL;
	}

	/* Get the reference to the defined td and corresponding skbuf.
	 */
	p_td = &p_pipe->p_tdr_start[p_pipe->old_tail];
	skb = p_pipe->skbr_start[p_pipe->old_tail];

	p_pipe->nr_of_queued_entries--;
	p_pipe->old_tail++;
	if (p_pipe->old_tail >= p_pipe->nr_of_entries)
		p_pipe->old_tail = 0;

	if (!p_td || !skb || !p_td->buffer.address) {
		ipc_err("Either of the pointer is NULL");
		return NULL;
	}

	if (p_td->buffer.address != ((struct ipc_skb_cb *)(skb->cb))->mapping) {
		ipc_err("pipe(%d): invalid buf_addr=%llx or skb->data=%llx",
			p_pipe->pipe_nr, p_td->buffer.address,
			skb ? ((struct ipc_skb_cb *)(skb->cb))->mapping : 0);
		return NULL;
	}

	return skb;
}


/**
 * Allocates an SKB for CP to send data and updates the Head Pointer
 * of the given Pipe#.
 *
 * @this_p: Valid pointer which can be typecasted to ipc_legacy.
 * @p_pipe: Pointer to pipe
 *
 * returns True if CP gets a new TD or False otherwise.
 */
static bool ipc_legacy_dl_td_prepare(void *this_p, struct ipc_pipe *p_pipe)
{
	struct ipc_legacy_td *td;
	ipc_mem_head_ptr_t head, new_head;
	ipc_mem_tail_ptr_t tail;
	struct sk_buff *skb;
	u64 mapping = 0;
	struct ipc_legacy *this = this_p;

	if (unlikely(!this || !p_pipe)) {
		ipc_err("Invalid arg(s)");
		return false;
	}

	/* Get head and tail of the td list and calculate
	 * the number of free elements.
	 */
	head = this->p_ap_shm->head_ptr_array[p_pipe->pipe_nr];
	tail = this->p_ap_shm->tail_ptr_array[p_pipe->pipe_nr];

	new_head = head + 1;
	if (new_head >= p_pipe->nr_of_entries)
		new_head = 0;

	if (new_head == tail)
		return false;

	/* Get the td address.
	 */
	td = &p_pipe->p_tdr_start[head];

	/* Allocate the skbuf for the descriptor. */
	skb = ipc_pcie_alloc_dl_skb(this->p_pcie, p_pipe->buf_size, &mapping);
	if (!skb) {
		ipc_err("pipe(%d): exhausted skbuf DL memory",
			p_pipe->pipe_nr);
		ipc_trc_dl_mem_alloc_fail(p_pipe->buf_size);
		return false;
	}

	td->buffer.address = mapping;
	td->scs.size = p_pipe->buf_size;
	td->scs.completion_status = 0;
	td->next = 0;
	td->reserved1 = 0;

	/* store the new head value.
	 */
	this->p_ap_shm->head_ptr_array[p_pipe->pipe_nr] = new_head;
	ipc_dbg("pipe:%d old_head: %d, head: %d, tail: %d", p_pipe->pipe_nr,
			head, new_head, tail);

	/* Save the reference to the skbuf.
	 */
	p_pipe->skbr_start[head] = skb;

	p_pipe->nr_of_queued_entries++;

	return true;
}


/**
 * Processes the TD processed from CP by checking the Tail Pointer for given
 * pipe.
 *
 * @this_p: Valid pointer which can be typecasted to ipc_legacy.
 * @p_pipe: Pointer to pipe
 *
 * returns pointer of struct sk_buff if CP has processed tail pinter or NULL
 * otherwise.
 */
static struct sk_buff *ipc_legacy_dl_td_process(void *this_p,
		struct ipc_pipe *p_pipe)
{
	struct ipc_legacy_td *p_td;
	ipc_mem_tail_ptr_t tail;
	struct sk_buff *skb;
	struct ipc_skb_cb *skb_cb = NULL;
	struct ipc_legacy *this = this_p;

	if (unlikely(!this || !p_pipe)) {
		ipc_err("Invalid arg(s)");
		return NULL;
	}

	tail = this->p_ap_shm->tail_ptr_array[p_pipe->pipe_nr];

	if (!p_pipe->p_tdr_start)
		return NULL;

	/* Copy the reference to the downlink buffer.
	 */
	p_td = &p_pipe->p_tdr_start[p_pipe->old_tail];
	skb = p_pipe->skbr_start[p_pipe->old_tail];

	/* Reset the ring elements.
	 */
	p_pipe->skbr_start[p_pipe->old_tail] = NULL;

	/* decrement nr of queued entries.
	 */
	p_pipe->nr_of_queued_entries--;

	p_pipe->old_tail++;
	if (p_pipe->old_tail >= p_pipe->nr_of_entries)
		p_pipe->old_tail = 0;

	if (!skb || !skb->data) {
		ipc_err("skb is null");
		goto ret;
	} else if (!p_td || !p_td->buffer.address) {
		ipc_err("td/buffer address is null");
		ipc_pcie_kfree_skb(this->p_pcie, skb);
		skb = NULL;
		goto ret;
	}

	skb_cb = (struct ipc_skb_cb *)skb->cb;
	if (!skb_cb) {
		ipc_err("Pipe# %d, tail: %d skb_cb is NULL", p_pipe->pipe_nr,
				tail);
		ipc_pcie_kfree_skb(this->p_pcie, skb);
		skb = NULL;
		goto ret;
	}

	if (p_td->buffer.address != skb_cb->mapping) {
		ipc_err("invalid buf=%llX or skb=%p",
			p_td->buffer.address, skb->data);
		ipc_pcie_kfree_skb(this->p_pcie, skb);
		skb = NULL;
		goto ret;
	} else if (p_td->scs.size > p_pipe->buf_size) {
		ipc_err("invalid buffer size %d > %d",
			p_td->scs.size, p_pipe->buf_size);
		ipc_pcie_kfree_skb(this->p_pcie, skb);
		skb = NULL;
		goto ret;
	} else if (p_td->scs.completion_status == IPC_MEM_TD_CS_ABORT) {
		/* Discard aborted buffers.
		 */
		ipc_dbg("discard 'aborted' buffers");
		ipc_pcie_kfree_skb(this->p_pcie, skb);
		skb = NULL;
		goto ret;
	}

	/* Set the length field an truesize in skbuf.
	 */
	skb_put(skb, p_td->scs.size);
	skb->truesize = SKB_TRUESIZE(p_td->scs.size);

	/* DMA sync for ARM based platform only.
	 */
	ipc_pcie_sync_skb_for_cpu(this->p_pcie, skb);

ret:
	return skb;
}


/**
 * Returns the Head and Tail index of given pipe.
 *
 * @this_p: Valid pointer which can be typecasted to ipc_legacy.
 * @p_pipe: Pointer to pipe
 * @p_head: Pointer to get Head index. Passing NULL means caller is not
 *          interested.
 * @p_tail: Pointer to get Tail index. Passing NULL means caller is not
 *          interested.
 *
 * returns none.
 */
static void ipc_legacy_get_head_tail_index(void *this_p,
		struct ipc_pipe *p_pipe, u32 *p_head, u32 *p_tail)
{
	struct ipc_legacy *this = this_p;

	if (unlikely(!this || !p_pipe)) {
		ipc_err("Invalid arg(s)");
		return;
	}

	if (p_head)
		*p_head = this->p_ap_shm->head_ptr_array[p_pipe->pipe_nr];

	if (p_tail)
		*p_tail = this->p_ap_shm->tail_ptr_array[p_pipe->pipe_nr];
}


/**
 * Frees the TDs given to CP.
 *
 * @this_p: Valid pointer which can be typecasted to ipc_legacy.
 * @p_pipe: Pointer to pipe
 *
 * returns none.
 */
static void ipc_legacy_pipe_cleanup(void *this_p, struct ipc_pipe *p_pipe)
{
	struct sk_buff *skb;
	ipc_mem_head_ptr_t head;
	ipc_mem_tail_ptr_t tail;
	struct ipc_legacy *this = this_p;

	if (unlikely(!this || !p_pipe)) {
		ipc_err("Invalid arg(s)");
		return;
	}

	if (unlikely(!this->p_ap_shm)) {
		ipc_err("p_ap_shm is NULL");
		return;
	}

	/* Get the start and the end of the buffer list.
	 */
	head = this->p_ap_shm->head_ptr_array[p_pipe->pipe_nr];
	tail = p_pipe->old_tail;

	/* Reset tail and head, means set head and tail to 0.
	 */
	this->p_ap_shm->tail_ptr_array[p_pipe->pipe_nr] = 0;
	this->p_ap_shm->head_ptr_array[p_pipe->pipe_nr] = 0;

	/* Free pending uplink and downlink buffers.
	 */
	if (p_pipe->skbr_start) {
		while (head != tail) {
			/* Get the reference to the skbuf,
			 * which is on the way and free it.
			 */
			skb = p_pipe->skbr_start[tail];
			if (skb)
				ipc_pcie_kfree_skb(this->p_pcie, skb);

			tail++;
			if (tail >= p_pipe->nr_of_entries)
				tail = 0;
		}

		ipc_util_kfree(p_pipe->skbr_start);
		p_pipe->skbr_start = NULL;
	}

	p_pipe->old_tail = 0;

	/* Free and reset the td and skbuf circular buffers. kfree is save!
	 */
	if (p_pipe->p_tdr_start) {
		ipc_pcie_kfree(this->p_pcie, p_pipe->p_tdr_start,
			sizeof(struct ipc_legacy_td) * p_pipe->nr_of_entries,
			p_pipe->phy_tdr_start);

		p_pipe->p_tdr_start = NULL;
	}
}


/**
 * Get IPC status.
 *
 * @this_p: Valid pointer which can be typecasted to ipc_legacy.
 *
 * returns IPC status from AP shared memory peripheral info.
 */
static enum ipc_mem_device_ipc_state ipc_legacy_get_ipc_status(void *this_p)
{
	struct ipc_legacy *this = this_p;

	return (enum ipc_mem_device_ipc_state)
			this->p_ap_shm->device_info.ipc_status;
}


/**
 * Get Execution stage from AP shared memory.
 *
 * @this_p: Valid pointer which can be typecasted to ipc_legacy.
 *
 * returns execution stage from AP shared memory peripheral info.
 */
static enum ipc_mem_exec_stage ipc_legacy_get_ap_exec_stage(void *this_p)
{
	struct ipc_legacy *this = this_p;

	return (enum ipc_mem_exec_stage)
			this->p_ap_shm->device_info.execution_stage;
}

static int ipc_legacy_msg_prep(void *instance, enum ipc_msg_prep_type msg_type,
	union ipc_msg_prep_args *args)
{
	struct ipc_legacy *this = instance;

	if (!this || !args) {
		ipc_err("invalid arguments");
		return -1;
	}

	switch (msg_type) {

	case IPC_MSG_PREP_SLEEP:
		return ipc_legacy_msg_prep_sleep(this, args);

	case IPC_MSG_PREP_PIPE_OPEN:
		return ipc_legacy_msg_prep_pipe_open(this, args);

	case IPC_MSG_PREP_PIPE_CLOSE:
		return ipc_legacy_msg_prep_pipe_close(this, args);

	case IPC_MSG_PREP_FEATURE_SET:
		return ipc_legacy_msg_prep_feature_set(this, args);

		/* Unsupported messages in legacy protocol */
	case IPC_MSG_PREP_MAP:
	case IPC_MSG_PREP_UNMAP:
	default:
		ipc_err("unsupported message type:%d in legacy protocol",
			msg_type);
		return -1;
	}
}


/**
 * Returns Device sleep notification
 *
 * @this_p: Valid pointer which can be typecasted to ipc_legacy.
 *
 * returns device sleep notification value from AP shared memory peripheral
 *         info
 */
static u32 ipc_legacy_pm_dev_get_sleep_notification(void *this_p)
{
	struct ipc_legacy *this = this_p;

	return  this->p_ap_shm->device_info.device_sleep_notification;
}


/*
 * Prints Message ring statistics into seq_file.
 *
 * @this_p: Valid pointer which can be typecasted to ipc_legacy.
 * @m: seq_file to print statistics into.
 *
 * returns none
 */
static void ipc_legacy_print_stats(void *this_p, struct seq_file *m)
{
	struct ipc_legacy *this = this_p;

	if (unlikely(!this || !m)) {
		ipc_err("Invalid argument(s)");
		return;
	}

	seq_printf(m, "MSG head.............: %u\n",
		this->p_ap_shm->msg_head_ptr);
	seq_printf(m, "MSG tail.............: %u\n",
		this->p_ap_shm->msg_tail_ptr);
	seq_printf(m, "MSG entries..........: %u\n\n",
		this->p_ap_shm->ci.msg_ring_entries);
}


/**
 * Destructor for Legacy protocol instance
 *
 * @this: ipc_legacy instance pointer
 *
 * returns none
 */
static void ipc_legacy_dtor(struct ipc_legacy *this)
{
	ipc_pcie_kfree(this->p_pcie, this->p_ap_shm,
		sizeof(struct ipc_legacy_ap_shm),
		this->phy_ap_shm);

	this->p_ap_shm = NULL;
}


/**
 * Deallocates IPC Legacy protocol instance
 *
 * @this: Pointer to the pointer to the IPC Legacy protocol instance
 *
 * returns None
 */
static void ipc_protocol_legacy_dealloc(void **this_pp)
{
	struct ipc_legacy **this = (struct ipc_legacy **)this_pp;

	if (this && *this) {
		ipc_legacy_dtor(*this);
		ipc_util_kfree(*this);
		*this = NULL;
	}
}


/*
 * Constructor for Legacy protocol instance
 *
 * @this: ipc_legacy instance pointer
 * @p_pcie: Instance pointer  of PCIe module.
 * @p_stats: Instance pointer to Stats module.
 * @p_mmio: Instance pointer of MMIO module.
 * @p_params: Instance pointer to Params module
 * @p_pm: Instance pointer to PM module
 * @ops: Pointer to structure of function pointers to support protocol
 * @dbg: pointer to ipc_dbg structure
 *
 * returns 0 on Success and -1 on failure
 */
static int ipc_legacy_ctor(struct ipc_legacy *this,
		struct ipc_pcie *p_pcie, struct ipc_debugfs_stats *p_stats,
		struct ipc_mmio *p_mmio, struct ipc_params *p_params,
		struct ipc_pm *p_pm, struct ipc_protocol_ops *ops,
		struct ipc_dbg *dbg)
{
	u64 addr;
	struct ipc_legacy_context_info *p_ci;

	if (unlikely(!p_pcie || !p_mmio || !p_params || !p_pm || !ops)) {
		ipc_err("Invalid args");
		return -1;
	}

	this->p_pcie = p_pcie;
	this->p_stats = p_stats;
	this->pm = p_pm;
	this->dbg = dbg;

	this->p_ap_shm = ipc_pcie_kzalloc(p_pcie, sizeof(*this->p_ap_shm),
		&this->phy_ap_shm);
	if (!this->p_ap_shm) {
		ipc_err("alloc error");
		return -1;
	}

	/* Prepare the context info for CP.
	 */
	addr = this->phy_ap_shm;
	p_ci = &this->p_ap_shm->ci;
	p_ci->device_info_addr = addr + offsetof(struct ipc_legacy_ap_shm,
				device_info);
	p_ci->head_ptr_array = addr + offsetof(struct ipc_legacy_ap_shm,
				head_ptr_array);
	p_ci->tail_ptr_array = addr + offsetof(struct ipc_legacy_ap_shm,
				tail_ptr_array);
	p_ci->msg_head_ptr = addr + offsetof(struct ipc_legacy_ap_shm,
				msg_head_ptr);
	p_ci->msg_tail_ptr = addr + offsetof(struct ipc_legacy_ap_shm,
				msg_tail_ptr);
	p_ci->msg_ring_addr = addr + offsetof(struct ipc_legacy_ap_shm,
				msg_ring);
	p_ci->msg_ring_entries = IPC_MEM_MSG_ENTRIES;
	p_ci->msg_irq_vector = IPC_MSG_IRQ_VECTOR;
	p_ci->device_info_irq_vector = IPC_DEVICE_IRQ_VECTOR;

	/* Set the Context info address in MMIO */
	ipc_mmio_set_contex_info_addr(p_mmio, addr);

	this->old_msg_tail_ptr = 0;

	ops->msg_prep = ipc_legacy_msg_prep;
	ops->msg_hp_update = ipc_legacy_msg_hp_update;
	ops->msg_process = ipc_legacy_msg_process;
	ops->ul_td_process = ipc_legacy_ul_td_process;
	ops->dl_td_process = ipc_legacy_dl_td_process;
	ops->ul_td_send = ipc_legacy_ul_td_send;
	ops->dl_td_prepare = ipc_legacy_dl_td_prepare;
	ops->get_head_tail_index = ipc_legacy_get_head_tail_index;
	ops->get_ipc_status = ipc_legacy_get_ipc_status;
	ops->pipe_cleanup = ipc_legacy_pipe_cleanup;
	ops->get_ap_exec_stage = ipc_legacy_get_ap_exec_stage;
	ops->pm_dev_get_sleep_notification =
		ipc_legacy_pm_dev_get_sleep_notification;
	ops->print_stats = ipc_legacy_print_stats;
	ops->protocol_dealloc = ipc_protocol_legacy_dealloc;

	return 0;
}


/*
 * Refer to header file for description
 */
void *ipc_protocol_legacy_alloc(struct ipc_pcie *p_pcie,
		struct ipc_debugfs_stats *p_stats, struct ipc_mmio *p_mmio,
		struct ipc_params *p_params, struct ipc_pm *p_pm,
		struct ipc_protocol_ops *ops, struct ipc_dbg *dbg)
{
	struct ipc_legacy *this = ipc_util_kzalloc(sizeof(*this));

	if (this) {
		if (ipc_legacy_ctor(this, p_pcie, p_stats, p_mmio,
					p_params, p_pm, ops, dbg)) {
			ipc_err("Protocol legacy constructor failed!");
			ipc_protocol_legacy_dealloc((void **)&this);
			return NULL;
		}
	}

	return this;
}

